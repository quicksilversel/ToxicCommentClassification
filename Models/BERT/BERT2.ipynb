{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJRKieB5L0oC",
        "outputId": "08ab35eb-64ad-4166-9819-38a8204a1167"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "jigsaw-toxic-comment-classification-challenge.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  jigsaw-toxic-comment-classification-challenge.zip\n",
            "replace sample_submission.csv.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace test.csv.zip? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.6)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n"
          ]
        }
      ],
      "source": [
        "import os.path\n",
        "from os import path\n",
        "\n",
        "if not path.exists(\"kaggle.json\"):\n",
        "  raise Exception(\"Please upload kaggle.json. See https://www.kaggle.com/docs/api \")\n",
        "\n",
        "! pip install kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "! unzip jigsaw-toxic-comment-classification-challenge.zip\n",
        "! pip install transformers\n",
        "! pip install pyyaml h5py # For saving model in h5 format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4LdFAQdLniZ",
        "outputId": "772b4900-882d-4fc4-b3de-64c282a96925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import transformers\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "SEED = 1\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WafDC1NRLt_L"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('train.csv.zip')\n",
        "test = pd.read_csv('test.csv.zip')\n",
        "test_labels = pd.read_csv('test_labels.csv.zip')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "At0u7pwFqlrG"
      },
      "outputs": [],
      "source": [
        "LABELS = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "N_LABELS = len(LABELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wXxKgbdO0mcV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "upgcowLEMOjN"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "def preprocessComments(comment):\n",
        "    # Convert to lowercase, important for this bertmodel\n",
        "    comment = comment.lower()\n",
        "\n",
        "    # Remove leading and trailing spaces\n",
        "    comment = comment.strip()\n",
        "\n",
        "    # Remove consecutive spaces      \n",
        "    comment = re.sub(r' +', ' ', comment)\n",
        "\n",
        "    # Remove Newlines\n",
        "    comment = re.sub(r'\\n', ' ', comment)\n",
        "\n",
        "    return comment\n",
        "\n",
        "train.comment_text = train.comment_text.map(preprocessComments)\n",
        "train_y = train[LABELS].values\n",
        "test.comment_text = test.comment_text.map(preprocessComments)\n",
        "\n",
        "if train['comment_text'].isnull().values.any():\n",
        "  raise Exception(\"Missing data\")\n",
        "if test['comment_text'].isnull().values.any():\n",
        "  raise Exception(\"Missing data\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpgKN3wa0ohr",
        "outputId": "4d4ac090-3c7d-4971-d8d5-0c419d7d93b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(63978, 8)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "63978"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_filtered = pd.merge(test, test_labels)\n",
        "test_filtered = test_filtered.drop(test_filtered.index[test_filtered['toxic'] == -1])\n",
        "comments_list = train['comment_text'].tolist()\n",
        "test_comments_list = test_filtered['comment_text'].tolist()\n",
        "print(test_filtered.shape)\n",
        "len(test_comments_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhqII4yQqcyW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMsuJrSRMTtd",
        "outputId": "f2c9f66a-c125-4de5-821b-bc313fe2264d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "bert_name = \"bert-base-uncased\"\n",
        "\n",
        "bert_model = transformers.TFAutoModel.from_pretrained(bert_name)\n",
        "\n",
        "tokenizer = transformers.BertTokenizerFast.from_pretrained(\n",
        "    pretrained_model_name_or_path=bert_name, \n",
        "    config=transformers.BertConfig.from_pretrained(bert_name))\n",
        "\n",
        "TOKENS_MAX_LENGTH = 120\n",
        "\n",
        "def create_tokenizer(comments):\n",
        "  return tokenizer(\n",
        "    text=comments,\n",
        "    padding='longest', \n",
        "    truncation='longest_first',\n",
        "    max_length=TOKENS_MAX_LENGTH,\n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True)\n",
        "  \n",
        "train_tokenizer = create_tokenizer(comments_list)\n",
        "test_tokenizer = create_tokenizer(test_comments_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zt9JANJcMVtS"
      },
      "outputs": [],
      "source": [
        "from pandas.core.common import random_state\n",
        "att_mask = tf.keras.layers.Input(shape=(TOKENS_MAX_LENGTH,), name='attention_mask', dtype='int32') \n",
        "input_ids = tf.keras.layers.Input(shape=(TOKENS_MAX_LENGTH,), name='input_ids', dtype='int32')\n",
        "input = {'attention_mask': att_mask, 'input_ids': input_ids}\n",
        "x = bert_model.bert(input)\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x[0])\n",
        "# x = tf.keras.layers.Flatten()(x[0])\n",
        "x = tf.keras.layers.Dense(N_LABELS, activation='sigmoid')(x)\n",
        "model = tf.keras.models.Model(input, x)\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-5),\n",
        "    metrics=['acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puxYIaTdMg_Y",
        "outputId": "957ac809-0427-4c00-b302-00f458b38af7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "1995/1995 [==============================] - 3353s 2s/step - loss: 0.0499 - acc: 0.9146 - val_loss: 0.0457 - val_acc: 0.9756\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89d041eb50>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    {'attention_mask': train_tokenizer['attention_mask'], 'input_ids': train_tokenizer['input_ids']},\n",
        "    train_y,\n",
        "    validation_split=0.2,\n",
        "    epochs=1,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "M2-gSkTuEA68"
      },
      "outputs": [],
      "source": [
        "# Save model weights\n",
        "\n",
        "!mkdir -p saved_model\n",
        "model.save('saved_model/bert.h5') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAEEx7NcGZiI",
        "outputId": "9bf81dc2-ac28-43b2-d9f8-47dd71f7d296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 516s 513ms/step\n"
          ]
        }
      ],
      "source": [
        "predictions = model.predict(\n",
        "    {'attention_mask': test_tokenizer['attention_mask'], 'input_ids': test_tokenizer['input_ids']},\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d3boU3018-Y",
        "outputId": "a5fc9037-b3a6-4210-c0fd-714d3dd11674"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxic :\n",
            "0.6588192017656797\n",
            "severe_toxic :\n",
            "0.36594202898550726\n",
            "obscene :\n",
            "0.6325704059527174\n",
            "threat :\n",
            "0.26732673267326734\n",
            "insult :\n",
            "0.6399262332872291\n",
            "identity_hate :\n",
            "0.4471243042671614\n",
            "Average f1-score: 0.5019514844885937\n"
          ]
        }
      ],
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(LABELS):\n",
        "    print(label, \":\")\n",
        "    pb = predictions[:, i] >= 0.5\n",
        "    score = f1_score(test_filtered[label], pb)\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= N_LABELS\n",
        "print(\"Average f1-score:\", avg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
