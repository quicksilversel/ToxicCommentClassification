{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CS470_LogisticRegression.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DeX6e8Mn4K5","executionInfo":{"status":"ok","timestamp":1653532965499,"user_tz":-540,"elapsed":27932,"user":{"displayName":"Zoe","userId":"18109677899978990401"}},"outputId":"d15596fe-5ee1-4ea1-9711-40f2dc8d540f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","import numpy as np \n","import pandas as pd \n","\n","import re\n","import string\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import f1_score\n","from sklearn.linear_model import LogisticRegression\n","\n","import nltk\n","from nltk.corpus import stopwords                  # module for stop words that come with NLTK\n","from nltk.stem.wordnet import WordNetLemmatizer    # module for lemmatization\n","from nltk import word_tokenize, pos_tag            # tokenization and Part of Speech tagging\n","\n","nltk.download('stopwords')\n","stopwords_english = stopwords.words('english') # English stopwords\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","source":["# data\n","train = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/train.csv')\n","test = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/test.csv')\n","test_label = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/test_labels.csv')\n","\n","# data info\n","train.info()\n","train.head(10)\n","\n","# the % of toxic comments\n","test_label = test_label.loc[test_label['toxic']!=-1]\n","test_label.iloc[:,1:-1].sum(axis=0) / test_label.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NSeqkgSTTXDa","executionInfo":{"status":"ok","timestamp":1653532976684,"user_tz":-540,"elapsed":9739,"user":{"displayName":"Zoe","userId":"18109677899978990401"}},"outputId":"623b5233-028f-48ad-f497-e3c06b7ffbf3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 159571 entries, 0 to 159570\n","Data columns (total 8 columns):\n"," #   Column         Non-Null Count   Dtype \n","---  ------         --------------   ----- \n"," 0   id             159571 non-null  object\n"," 1   comment_text   159571 non-null  object\n"," 2   toxic          159571 non-null  int64 \n"," 3   severe_toxic   159571 non-null  int64 \n"," 4   obscene        159571 non-null  int64 \n"," 5   threat         159571 non-null  int64 \n"," 6   insult         159571 non-null  int64 \n"," 7   identity_hate  159571 non-null  int64 \n","dtypes: int64(6), object(2)\n","memory usage: 9.7+ MB\n"]},{"output_type":"execute_result","data":{"text/plain":["toxic           0.095189\n","severe_toxic    0.005736\n","obscene         0.057692\n","threat          0.003298\n","insult          0.053565\n","dtype: float64"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["# preprocess the comments\n","\n","# From a string, make text lowercase, remove hyperlinks, punctuation, word containing numbers, stopwords.\n","# Input : a list of string\n","# Output : a list of tokens stored in a generator (yield)\n","\n","def preprocess(corpus):\n","\n","    for text in corpus:\n","\n","        text = text.lower()                                               # Lowercase\n","        text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)                   # Remove links\n","        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)   # Remove punctuation\n","        text = re.sub('\\w*\\d\\w*', '', text)                               # Remove words containing numbers\n","    \n","        yield ' '.join([word for word in text.split(' ') if word not in stopwords_english]) # Return a generator \n","\n","# clean comments to be fed\n","clean_comments = list(preprocess(train['comment_text']))"],"metadata":{"id":"X54vZWXoTRZo","executionInfo":{"status":"ok","timestamp":1653533016458,"user_tz":-540,"elapsed":37373,"user":{"displayName":"Zoe","userId":"18109677899978990401"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# logistic regression model\n","\n","labels = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']\n","\n","vectorizer = TfidfVectorizer(analyzer='word',\n","                            stop_words='english',\n","                            ngram_range=(1, 3),\n","                            max_features=30000,\n","                            sublinear_tf=True)\n","X_train = vectorizer.fit_transform(train.comment_text)\n","X_test = vectorizer.transform(test.comment_text)\n","Y_train = train[labels]\n","\n","submission = pd.DataFrame.from_dict({'id': test['id']})\n","\n","# calculate cross validated f1 scores\n","\n","scores = []\n","\n","for label in labels:\n","    #build classifier\n","    LR = LogisticRegression(solver='saga', n_jobs=-1, C=0.5)\n","    \n","    #compute cv score\n","    cv_score = np.mean(cross_val_score(LR, X_train, Y_train[label], cv=3, n_jobs=-1, scoring='f1'))\n","    scores.append(cv_score)\n","    print(\"F1 score for class {} is {}\".format(label, cv_score))\n","    \n","    #re-learn & predict\n","    LR.fit(X_train, Y_train[label])  \n","    submission[label] = LR.predict_proba(X_test)[:, 1] #predict\n","    \n","print(\"Average Cross Validated F1 scores: {}\".format(np.mean(scores)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BEPtw8GRRdHh","executionInfo":{"status":"ok","timestamp":1653533165812,"user_tz":-540,"elapsed":144440,"user":{"displayName":"Zoe","userId":"18109677899978990401"}},"outputId":"d5d70be1-50e0-40e5-b494-55535407c8e3"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["F1 score for class toxic is 0.6598846803476125\n","F1 score for class severe_toxic is 0.23718403484316655\n","F1 score for class obscene is 0.6928714547173908\n","F1 score for class threat is 0.0401199152872513\n","F1 score for class insult is 0.5693808193729556\n","F1 score for class identity_hate is 0.15608408432807697\n","Average Cross Validated F1 scores: 0.3925874981494089\n"]}]}]}