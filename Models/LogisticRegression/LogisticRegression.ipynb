{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Word Embedding Method : TF-IDF"
      ],
      "metadata": {
        "id": "s1FWZUGcG9AW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-DeX6e8Mn4K5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420d1ad7-b29d-4f11-efd4-07a9fcf1b3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords                  # module for stop words that come with NLTK\n",
        "from nltk.stem.wordnet import WordNetLemmatizer    # module for lemmatization\n",
        "from nltk import word_tokenize, pos_tag            # tokenization and Part of Speech tagging\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stopwords_english = stopwords.words('english') # English stopwords\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Manipulation"
      ],
      "metadata": {
        "id": "XNxrLWW9HGTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/train.csv')\n",
        "test_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/test.csv')\n",
        "test_label_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Data/test_labels.csv')\n",
        "\n",
        "# use only rows that were used for scoring\n",
        "test_label_data = test_label_data.loc[test_label_data['toxic']!=-1]\n",
        "test = test_label_data.merge(test_data, on='id', how=\"inner\")"
      ],
      "metadata": {
        "id": "NSeqkgSTTXDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca089390-8d61-41ff-8029-4a654db81513"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess the comments\n",
        "\n",
        "# From a string, make text lowercase, remove hyperlinks, punctuation, word containing numbers, stopwords.\n",
        "# Input : a list of string\n",
        "# Output : a list of tokens stored in a generator (yield)\n",
        "\n",
        "def preprocess(corpus):\n",
        "\n",
        "    for text in corpus:\n",
        "\n",
        "        text = text.lower()                                               # Lowercase\n",
        "        text = re.sub(r'https?://[^\\s\\n\\r]+', '', text)                   # Remove links\n",
        "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)   # Remove punctuation\n",
        "        text = re.sub('\\w*\\d\\w*', '', text)                               # Remove words containing numbers\n",
        "    \n",
        "        yield ' '.join([word for word in text.split(' ') if word not in stopwords_english]) # Return a generator \n",
        "\n",
        "# proprocessed train dataset\n",
        "clean_comments = list(preprocess(train_data['comment_text']))\n",
        "# preprocessed test dataset\n",
        "test_clean_comments = list(preprocess(test['comment_text']))\n",
        "\n",
        "labels = ['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']"
      ],
      "metadata": {
        "id": "X54vZWXoTRZo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word embedding : TF-IDF\n",
        "tfidf_vec = TfidfVectorizer(min_df=1,max_df=0.9)\n",
        "\n",
        "X_train = tfidf_vec.fit_transform(clean_comments)\n",
        "X_test = tfidf_vec.transform(test_clean_comments)\n",
        "Y_train = train_data[labels]\n",
        "\n",
        "submission = pd.DataFrame.from_dict({'id': test['id']})"
      ],
      "metadata": {
        "id": "BEPtw8GRRdHh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "oa7xg5UFK7oi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Model and calculate f1 scores\n",
        "\n",
        "f1_scores = []\n",
        "\n",
        "for label in labels:\n",
        "\n",
        "    # Model\n",
        "    LR = LogisticRegression(solver='saga', n_jobs=-1, C=0.5)\n",
        "    \n",
        "    # Calculate F1-score\n",
        "    f1_score = np.mean(cross_val_score(LR, X_train, Y_train[label], cv=3, n_jobs=-1, scoring='f1'))\n",
        "    f1_scores.append(f1_score)\n",
        "    print(\"F1 score for class {} is {}\".format(label, f1_score))\n",
        "    \n",
        "    # re-learn & predict\n",
        "    LR.fit(X_train, Y_train[label])  \n",
        "    submission[label] = LR.predict_proba(X_test)[:, 1] # predict\n",
        "    \n",
        "print(\"Average F1 score: {}\".format(np.mean(f1_scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oSx3UgJHQmZ",
        "outputId": "f6f6c38d-6362-43c3-9a2b-eb19309e9387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score for class toxic is 0.6500233714915494\n",
            "F1 score for class severe_toxic is 0.2670401910132863\n",
            "F1 score for class obscene is 0.6779626665264592\n",
            "F1 score for class threat is 0.07482626248557024\n",
            "F1 score for class insult is 0.5520726719300045\n",
            "F1 score for class identity_hate is 0.15913335650561927\n",
            "Average F1 score: 0.39684308665874823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "\n",
        "scores = []\n",
        "\n",
        "for label in labels:\n",
        "\n",
        "    # Model\n",
        "    LR = LogisticRegression(solver='saga', n_jobs=-1, C=0.5)\n",
        "    \n",
        "    # Calculate F1-score\n",
        "    score = np.mean(cross_val_score(LR, X_train, Y_train[label], cv=3, n_jobs=-1, scoring='accuracy'))\n",
        "    scores.append(score)\n",
        "    print(\"Accuracy for class {} is {}\".format(label, score))\n",
        "    \n",
        "    # re-learn & predict\n",
        "    LR.fit(X_train, Y_train[label])  \n",
        "    submission[label] = LR.predict_proba(X_test)[:, 1] # predict\n",
        "    \n",
        "print(\"Average accuracy: {}\".format(np.mean(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HugzduIxoCTh",
        "outputId": "c45ccf47-0e1f-4441-f950-67c1d958922f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class toxic is 0.9488628905011796\n",
            "Accuracy for class severe_toxic is 0.9904368592197064\n",
            "Accuracy for class obscene is 0.9733159543012272\n",
            "Accuracy for class threat is 0.9970796704144117\n",
            "Accuracy for class insult is 0.9670679556928617\n",
            "Accuracy for class identity_hate is 0.9916212849613188\n",
            "Average accuracy: 0.9780641025151176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(submission)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV1lUgUA7Dis",
        "outputId": "d8959fc1-0f63-4eaa-cb28-9fa76d797a1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     id     toxic  severe_toxic   obscene    threat    insult  \\\n",
            "0      0001ea8717f6de06  0.007208      0.001675  0.004105  0.001158  0.005659   \n",
            "1      000247e83dcc1211  0.464248      0.007587  0.070421  0.003789  0.117398   \n",
            "2      0002f87b16116a7f  0.107364      0.003992  0.034280  0.001944  0.028534   \n",
            "3      0003e1cccfd5a40a  0.017246      0.003570  0.014727  0.001880  0.010983   \n",
            "4      00059ace3e3e9a53  0.004566      0.001144  0.003237  0.000846  0.003155   \n",
            "...                 ...       ...           ...       ...       ...       ...   \n",
            "63973  fff8f64043129fa2  0.008952      0.002335  0.006520  0.001624  0.005431   \n",
            "63974  fff9d70fe0722906  0.314890      0.020484  0.240443  0.003787  0.232633   \n",
            "63975  fffa8a11c4378854  0.323690      0.007994  0.048076  0.002788  0.056704   \n",
            "63976  fffac2a094c8e0e2  0.944271      0.072790  0.887506  0.004117  0.798352   \n",
            "63977  fffb5451268fb5ba  0.075470      0.006747  0.023806  0.002692  0.030217   \n",
            "\n",
            "       identity_hate  \n",
            "0           0.002040  \n",
            "1           0.008982  \n",
            "2           0.008190  \n",
            "3           0.004395  \n",
            "4           0.001171  \n",
            "...              ...  \n",
            "63973       0.002435  \n",
            "63974       0.013399  \n",
            "63975       0.017148  \n",
            "63976       0.043342  \n",
            "63977       0.007769  \n",
            "\n",
            "[63978 rows x 7 columns]\n"
          ]
        }
      ]
    }
  ]
}