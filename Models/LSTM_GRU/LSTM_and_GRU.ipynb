{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "plc9yt1MOIU4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cr81uesLUEFN"
      },
      "outputs": [],
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNXarWPI4jPI",
        "outputId": "6a68a64b-66c1-490b-fd5e-9a6b7683bc80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oUwQRdFZIiE4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCiWr2n7DSdw",
        "outputId": "6d6547fc-c058-4a69-f885-6bbf4f3021df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjvtMluBNF7j",
        "outputId": "c17eb51e-0238-4a71-ad71-31ab53a33fc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQ1VpnwNNdm",
        "outputId": "a60b02b1-e166-4ca6-d914-332c9ef52d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test.csv.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMGDxkqfNQ07",
        "outputId": "a37c6724-286f-4ff3-9b33-0312eb2ef488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/train.csv.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc15mw4PNqZn",
        "outputId": "a0248883-7832-4d99-ba1e-8df220dc121d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample_submission.csv.zip  test.csv.zip  test_labels.csv.zip  train.csv.zip\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/Kaggle/jigsaw-toxic-comment-classification-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yno3kSuOSkA",
        "outputId": "9724e219-2a64-461c-d9e7-7e1434e44a1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/test.csv\n"
          ]
        }
      ],
      "source": [
        "!realpath test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HYoUAnC6F_4T"
      },
      "outputs": [],
      "source": [
        "training_data = pd.read_csv(\"/content/train.csv\")\n",
        "testing_data = pd.read_csv(\"/content/test.csv\")\n",
        "testing_labels = pd.read_csv(\"/content/test_labels.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "eZE8M4lNPGMS"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqtErtBqIA_8",
        "outputId": "34130719-c4d6-436a-b805-f06ea164a6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-06-02 00:26:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-06-02 00:26:33--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-06-02 00:26:33--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.06MB/s    in 2m 40s  \n",
            "\n",
            "2022-06-02 00:29:13 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okBak-4IlpK",
        "outputId": "b8bb0760-176d-4752-b1bc-ce687e725d17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip  test.csv\t     train.csv\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data   test_labels.csv\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YJyzuOk1IJRV"
      },
      "outputs": [],
      "source": [
        "# EMBEDDING_FILE = \"glove.6B.50d.txt\"\n",
        "embedding = \"glove.6B.50d.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "DlKbOEcQ-PWN"
      },
      "outputs": [],
      "source": [
        "# size of embedding vector (total nb of words)\n",
        "max_len_embedding = 20000\n",
        "# size of each word\n",
        "size = 50\n",
        "# maximum length of a comment (in words)\n",
        "max_len = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fe4fXDoc-Q_r"
      },
      "outputs": [],
      "source": [
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "nb_labels = len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3aVNZINI3TAW"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "\n",
        "# Pattern form filtering english stopwords, taken from https://stackoverflow.com/questions/19560498/faster-way-to-remove-stop-words-in-python\n",
        "stopword_pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "\n",
        "def preprocess_data(text):\n",
        "\n",
        "  # Removing trailing spaces and leading spaces\n",
        "  text = text.strip()\n",
        "  # Lowercase\n",
        "  text = text.lower()\n",
        "  # Remove numbers\n",
        "  text = re.sub(r'[0-9]', '', text)\n",
        "  # Remove stopwords\n",
        "  text = stopword_pattern.sub('', text)\n",
        "  # Remove special characters\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # Remove consecutive spaces\n",
        "  text = re.sub(r' +', ' ', text)\n",
        "  # Remove new lines\n",
        "  text = re.sub(r'\\n', ' ', text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZVDjRLmA4WUM"
      },
      "outputs": [],
      "source": [
        "training_data.comment_text = training_data[\"comment_text\"].map(preprocess_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "o-ML6Dbw5UOk"
      },
      "outputs": [],
      "source": [
        "train_y = training_data[labels].fillna(\"_na_\").values\n",
        "testing_data.comment_text = testing_data[\"comment_text\"].map(preprocess_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsv53yCm5tq7",
        "outputId": "a36213b0-dddd-45c0-c616-be868ae1e7a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "63978"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testing_clean = pd.merge(testing_data, testing_labels)\n",
        "testing_clean = testing_clean.drop(testing_clean.index[testing_clean['toxic'] == -1])\n",
        "train_list = training_data['comment_text'].tolist()\n",
        "test_list = testing_clean['comment_text'].tolist()\n",
        "len(test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "YdPmbUHB23ZZ"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_len_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "z85JhLCX-eK4"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=max_len_embedding)\n",
        "tokenizer.fit_on_texts(train_list)\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(train_list)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(test_list)\n",
        "\n",
        "train_x = pad_sequences(list_tokenized_train, maxlen=max_len)\n",
        "test_x = pad_sequences(list_tokenized_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "-E2cRFir-fg0"
      },
      "outputs": [],
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embeddings_dict = dict(get_coefs(*elt.strip().split()) for elt in open(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL5I7zr7-hlq",
        "outputId": "81544f49-73fb-40cb-c1d2-3cb3826a4885"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.020940498\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6441043"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding_stack = np.stack(embeddings_dict.values())\n",
        "\n",
        "mean = embedding_stack.mean()\n",
        "std = embedding_stack.std()\n",
        "print(mean)\n",
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "JEhbVvdT-joa"
      },
      "outputs": [],
      "source": [
        "index = tokenizer.word_index\n",
        "total_words = min(max_len_embedding, len(index))\n",
        "embedding_matrix = np.random.normal(mean, std, (total_words, size))\n",
        "for word, i in index.items():\n",
        "    if i >= max_len_embedding: \n",
        "      continue\n",
        "    embedding_vector = index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "      embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZvIg5dB-l5h",
        "outputId": "58ac3480-dbed-48ac-9209-4ba7f83879e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 100)         40400     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 100)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,045,756\n",
            "Trainable params: 1,045,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[embedding_matrix]),\n",
        "  tf.keras.layers.Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "lstm_model.summary()\n",
        "\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5gPomvp-pkN",
        "outputId": "08e6e00f-6d45-425d-d7b5-1c8c77887961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 3773s 839ms/step - loss: 0.1418 - accuracy: 0.9628 - val_loss: 0.1403 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 3555s 792ms/step - loss: 0.1380 - accuracy: 0.9938 - val_loss: 0.1385 - val_accuracy: 0.9940\n"
          ]
        }
      ],
      "source": [
        "lstm_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIxf__h_-rwo",
        "outputId": "16cc3d86-a284-4d01-ea13-d5501d1125b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 5s 66ms/step\n"
          ]
        }
      ],
      "source": [
        "y_test_lstm = lstm_model.predict([test_x], batch_size=1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ombe74h6JOq5",
        "outputId": "5ec44b72-2d63-4c0f-91c7-5d2ac7021d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score_val_lstm = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_lstm, axis=1), average=\"weighted\")\n",
        "f1_score_val_lstm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V48Y1ouTTHju",
        "outputId": "843a8252-9735-4722-c826-b7673b27dcf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxic :\n",
            "0.8595949786595427\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9143192385431218\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.9440167788942615\n"
          ]
        }
      ],
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_lstm[:, i] >= 0.5\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSLkhIuKQWSi"
      },
      "outputs": [],
      "source": [
        "# GRU model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTFIvDSvQYg7",
        "outputId": "81b2800e-a13f-4574-c3bf-87514670b282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 100, 50)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100, 140)         51240     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 140)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                7050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,058,596\n",
            "Trainable params: 1,058,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gru_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[embedding_matrix]),\n",
        "  tf.keras.layers.SpatialDropout1D(0.3),\n",
        "  tf.keras.layers.Bidirectional(GRU(70, return_sequences=True)),  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "gru_model.summary()\n",
        "\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5YoOpVTFIpT",
        "outputId": "6a4504d9-1464-4062-a741-590f8de403cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 61s 12ms/step - loss: 0.1419 - accuracy: 0.9022 - val_loss: 0.1390 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 57s 13ms/step - loss: 0.1376 - accuracy: 0.9930 - val_loss: 0.1370 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1db6f3ff90>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fq3VvU-GJ42",
        "outputId": "72cf2120-60d8-4789-c8d3-b059d65045ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "y_test_gru = gru_model.predict([test_x], batch_size=1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmtSt9wGV07",
        "outputId": "76fb6f72-3297-40e9-c214-7fe6aae9ee37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score_val_gru = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_gru, axis=1), average=\"weighted\")\n",
        "f1_score_val_gru"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfnnhu22iCwl",
        "outputId": "502c5d86-65f9-4e59-ea3f-e591e8865ddb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxic :\n",
            "0.8595949786595427\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9143192385431218\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.9440167788942615\n"
          ]
        }
      ],
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_gru[:, i] >= 0.5\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52-uJYKviPns"
      },
      "outputs": [],
      "source": [
        "# GRU model is faster to train and performs just as good"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TDV-X3PGg50"
      },
      "outputs": [],
      "source": [
        "# subword embedding (fasttext) : trying to improve toxic obscene and insult labels f1 scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "HD6OW4dcIyHx"
      },
      "outputs": [],
      "source": [
        "fasttext_embedding_file = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshfOGd7julq",
        "outputId": "9c050e41-2ad3-417a-992a-efae44fa426a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGmBwaxmn8CU",
        "outputId": "d3560262-a860-4bf4-8815-93cc8d6651e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/Kaggle/crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n",
            "  inflating: __MACOSX/._crawl-300d-2M.vec  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/Kaggle/crawl-300d-2M.vec.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhyY0Q08oJGk",
        "outputId": "e5a6f3b7-803c-4752-ee5f-242a3035bfeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/crawl-300d-2M.vec\n"
          ]
        }
      ],
      "source": [
        "!realpath crawl-300d-2M.vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "PohxISiOj4a7"
      },
      "outputs": [],
      "source": [
        "fasttext_embedding_file = \"/content/crawl-300d-2M.vec\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "wP2K1J-CKB3Q"
      },
      "outputs": [],
      "source": [
        "fasttext_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(fasttext_embedding_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "2YtuIbPcj7ui"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPf11goBKHjV",
        "outputId": "158c4dee-85cb-4ec5-fbce-566bfdb53d63"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0055286596\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.34703913"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fasttext_stack = np.stack(fasttext_index.values())\n",
        "\n",
        "mean = fasttext_stack.mean()\n",
        "std = fasttext_stack.std()\n",
        "print(mean)\n",
        "std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "oXf8jIWyKVm5"
      },
      "outputs": [],
      "source": [
        "index = tokenizer.word_index\n",
        "total_words = min(max_len_embedding, len(index))\n",
        "fasttext_embedding_matrix = np.random.normal(mean, std, (total_words, size))\n",
        "for word, i in index.items():\n",
        "    if i >= max_len_embedding: continue\n",
        "    embedding_vector = index.get(word)\n",
        "    if embedding_vector is not None: fasttext_embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "WZj5DHcGK2Q1"
      },
      "outputs": [],
      "source": [
        "# Reimplementing the model with the better accuracy using subword embeddings (bidirectional GRU and LSTM models implemented have the same accuracy, so I chose GRU because it was faster during training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "BtEBZkpHivo7"
      },
      "outputs": [],
      "source": [
        "gru_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[fasttext_embedding_matrix]),\n",
        "  tf.keras.layers.SpatialDropout1D(0.3),\n",
        "  tf.keras.layers.Bidirectional(GRU(70, return_sequences=True)),  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZwS5d4qmGgP",
        "outputId": "ef99a4a4-47f5-483d-c3f3-24b673d6a640"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 100, 50)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 100, 140)         51240     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling1d_2   (None, 140)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                7050      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,058,596\n",
            "Trainable params: 1,058,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "gru_model.summary()\n",
        "\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJUPt9xtmLjZ",
        "outputId": "bbc97268-abfe-48f2-8c94-bfa379012a67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 59s 12ms/step - loss: 0.1414 - accuracy: 0.9064 - val_loss: 0.1416 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 55s 12ms/step - loss: 0.1375 - accuracy: 0.9933 - val_loss: 0.1371 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1db73e09d0>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gru_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOOn8AwqmTku",
        "outputId": "b10a92a8-353d-4389-f972-241af34759f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 2s 14ms/step\n"
          ]
        }
      ],
      "source": [
        "y_test_gru_ft = gru_model.predict([test_x], batch_size=1024, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gOIfzjRmYq2",
        "outputId": "cc105446-4b10-475a-d9d1-ad9e77e6d7ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score_val_gru_ft = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_gru_ft, axis=1), average=\"weighted\")\n",
        "f1_score_val_gru_ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnNbnTlLmdiL",
        "outputId": "afce87c3-9402-430b-8449-42a0bdb76994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "toxic :\n",
            "0.8595949786595427\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9143192385431218\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.9440167788942615\n"
          ]
        }
      ],
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_gru_ft[:, i] >= 0.5\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NP1LxbAxVcU"
      },
      "outputs": [],
      "source": [
        "# no real improvement"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM_and_GRU",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
