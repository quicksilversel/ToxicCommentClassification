{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_and_GRU",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "plc9yt1MOIU4"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import LSTM, GRU"
      ],
      "metadata": {
        "id": "cr81uesLUEFN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNXarWPI4jPI",
        "outputId": "62e02775-acde-43a6-840a-7203fd736f7c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "oUwQRdFZIiE4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCiWr2n7DSdw",
        "outputId": "3f8cb67b-2f49-4b33-b490-ce2bcbd01cb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjvtMluBNF7j",
        "outputId": "b7367959-2c58-4526-ae7d-d47c8277dc13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n",
            "  inflating: test_labels.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test.csv.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xeQ1VpnwNNdm",
        "outputId": "6abcca18-beeb-4aec-867f-a54e260ecb9d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n",
            "  inflating: test.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/My\\ Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/train.csv.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMGDxkqfNQ07",
        "outputId": "dcfb502d-945c-485b-ad20-5baada7d230d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/My Drive/Kaggle/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/Kaggle/jigsaw-toxic-comment-classification-challenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc15mw4PNqZn",
        "outputId": "607f786d-77fe-495c-bf80-b63a1d2a5a05"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv.zip  test.csv.zip  test_labels.csv.zip  train.csv.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!realpath test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yno3kSuOSkA",
        "outputId": "b5e83108-030e-4c30-d179-fb0613ecaab9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = pd.read_csv(\"/content/train.csv\")\n",
        "testing_data = pd.read_csv(\"/content/test.csv\")\n",
        "testing_labels = pd.read_csv(\"/content/test_labels.csv\")"
      ],
      "metadata": {
        "id": "HYoUAnC6F_4T"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "eZE8M4lNPGMS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqtErtBqIA_8",
        "outputId": "0206a688-1c95-4502-ef53-4bc014f5a1c2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-15 07:30:46--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-06-15 07:30:46--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-06-15 07:30:47--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 42s  \n",
            "\n",
            "2022-06-15 07:33:29 (5.07 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okBak-4IlpK",
        "outputId": "3868313e-858e-4280-95f4-872122d5a08d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip  test.csv\t     train.csv\n",
            "glove.6B.200d.txt  glove.6B.50d.txt   sample_data   test_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = \"glove.6B.50d.txt\""
      ],
      "metadata": {
        "id": "YJyzuOk1IJRV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size of embedding vector (total nb of words)\n",
        "max_len_embedding = 20000\n",
        "# size of each word\n",
        "size = 50\n",
        "# maximum length of a comment (in words)\n",
        "max_len = 100"
      ],
      "metadata": {
        "id": "DlKbOEcQ-PWN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "nb_labels = len(labels)"
      ],
      "metadata": {
        "id": "fe4fXDoc-Q_r"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing\n",
        "\n",
        "# Pattern form filtering english stopwords, taken from https://stackoverflow.com/questions/19560498/faster-way-to-remove-stop-words-in-python\n",
        "stopword_pattern = re.compile(r'\\b(' + r'|'.join(stopwords.words('english')) + r')\\b\\s*')\n",
        "\n",
        "def preprocess_data(text):\n",
        "\n",
        "  # Removing trailing spaces and leading spaces\n",
        "  text = text.strip()\n",
        "  # Lowercase\n",
        "  text = text.lower()\n",
        "  # Remove numbers\n",
        "  text = re.sub(r'[0-9]', '', text)\n",
        "  # Remove stopwords\n",
        "  text = stopword_pattern.sub('', text)\n",
        "  # Remove special characters\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  # Remove consecutive spaces\n",
        "  text = re.sub(r' +', ' ', text)\n",
        "  # Remove new lines\n",
        "  text = re.sub(r'\\n', ' ', text)\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "3aVNZINI3TAW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.comment_text = training_data[\"comment_text\"].map(preprocess_data)"
      ],
      "metadata": {
        "id": "ZVDjRLmA4WUM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = training_data[labels].fillna(\"_na_\").values\n",
        "testing_data.comment_text = testing_data[\"comment_text\"].map(preprocess_data)"
      ],
      "metadata": {
        "id": "o-ML6Dbw5UOk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_clean = pd.merge(testing_data, testing_labels)\n",
        "testing_clean = testing_clean.drop(testing_clean.index[testing_clean['toxic'] == -1])\n",
        "test_y = testing_clean[labels].fillna(\"_na_\").values\n",
        "train_list = training_data['comment_text'].tolist()\n",
        "test_list = testing_clean['comment_text'].tolist()\n",
        "len(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsv53yCm5tq7",
        "outputId": "e116911c-8148-4008-b2e7-97ec616dfd78"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63978"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_len_embedding)"
      ],
      "metadata": {
        "id": "YdPmbUHB23ZZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=max_len_embedding)\n",
        "tokenizer.fit_on_texts(train_list)\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(train_list)\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(test_list)\n",
        "\n",
        "train_x = pad_sequences(list_tokenized_train, maxlen=max_len)\n",
        "test_x = pad_sequences(list_tokenized_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "z85JhLCX-eK4"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embeddings_dict = dict(get_coefs(*elt.strip().split()) for elt in open(embedding))"
      ],
      "metadata": {
        "id": "-E2cRFir-fg0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_stack = np.stack(embeddings_dict.values())\n",
        "\n",
        "mean = embedding_stack.mean()\n",
        "std = embedding_stack.std()\n",
        "print(mean)\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL5I7zr7-hlq",
        "outputId": "4cb8bd9b-abbd-4cf2-b612-3932195e125f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.020940498\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6441043"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = tokenizer.word_index\n",
        "total_words = min(max_len_embedding, len(index))\n",
        "embedding_matrix = np.random.normal(mean, std, (total_words, size))\n",
        "for word, i in index.items():\n",
        "    if i >= max_len_embedding: \n",
        "      continue\n",
        "    embedding_vector = index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "      embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "JEhbVvdT-joa"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[embedding_matrix]),\n",
        "  tf.keras.layers.Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)),\n",
        "  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "lstm_model.summary()\n",
        "\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZvIg5dB-l5h",
        "outputId": "0b73ac80-0ebc-4b03-a961-37db4398bccc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 100)         40400     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 100)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                5050      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,045,756\n",
            "Trainable params: 1,045,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.1);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5gPomvp-pkN",
        "outputId": "1925b208-9a1b-406f-bde8-2ef199685516"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 3339s 742ms/step - loss: 0.1433 - accuracy: 0.9105 - val_loss: 0.1400 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 3322s 740ms/step - loss: 0.1391 - accuracy: 0.9928 - val_loss: 0.1404 - val_accuracy: 0.9940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_lstm = lstm_model.predict([test_x], batch_size=1024, verbose=1) \n",
        "y_test_lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIxf__h_-rwo",
        "outputId": "e0ddaa15-fc73-4b68-aa6d-0c141e60f00d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 4s 61ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11432589, 0.01262311, 0.06208618, 0.00296796, 0.06028283,\n",
              "        0.00849418],\n",
              "       [0.12836766, 0.01573337, 0.07240162, 0.00359868, 0.06993145,\n",
              "        0.01013626],\n",
              "       [0.0688803 , 0.00488057, 0.03219996, 0.00125635, 0.03127804,\n",
              "        0.00397293],\n",
              "       ...,\n",
              "       [0.12479429, 0.01491869, 0.06974557, 0.00343779, 0.06745971,\n",
              "        0.00971683],\n",
              "       [0.09921107, 0.00973108, 0.05154187, 0.00237311, 0.05038292,\n",
              "        0.00691643],\n",
              "       [0.09636432, 0.00922339, 0.04961004, 0.00226521, 0.04855976,\n",
              "        0.00662752]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_val_lstm = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_lstm, axis=1), average=\"weighted\")\n",
        "f1_score_val_lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ombe74h6JOq5",
        "outputId": "0b221689-a9c8-47a3-a4ec-a607f1226431"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_lstm[:, i] >= 0.1\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V48Y1ouTTHju",
        "outputId": "bc7821bf-163e-4ea4-ad00-c83828f0abb8"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic :\n",
            "0.6666223929095505\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9143192385431218\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.9118546812692627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# export results\n",
        "\n",
        "results = testing_clean.copy(deep=True)\n",
        "results[labels] = y_test_lstm\n",
        "\n",
        "results.to_csv(\"lstm_predictions.csv\")"
      ],
      "metadata": {
        "id": "z8cgjt5E5GtJ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!realpath lstm_predictions.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO3QD1D16nwy",
        "outputId": "a03f11a3-fa86-4d91-c3f4-3e6635a39088"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lstm_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU model"
      ],
      "metadata": {
        "id": "YSLkhIuKQWSi"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndQKZAGDJoc4",
        "outputId": "d1b0abe7-d692-4189-c057-2532c7d4ef00"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow_addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[embedding_matrix]),\n",
        "  tf.keras.layers.SpatialDropout1D(0.3),\n",
        "  tf.keras.layers.Bidirectional(GRU(70, return_sequences=True)),  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "gru_model.summary()\n",
        "\n",
        "# gru_model.compile(loss=tf.keras.losses.BinaryFocalCrossentropy(\n",
        "    # gamma=4.0,\n",
        "    # from_logits=False,\n",
        "    # label_smoothing=0.0,\n",
        "    # axis=-1,\n",
        "    # reduction=tf.keras.losses.Reduction.SUM,\n",
        "#     name='binary_focal_crossentropy'\n",
        "#     ), optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "# import tensorflow_addons as tfa\n",
        "# gru_model.compile(loss=tfa.losses.SigmoidFocalCrossEntropy(\n",
        "#     gamma=nb_labels,\n",
        "#     from_logits=False,\n",
        "#     reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE,\n",
        "# ), optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])\n",
        "\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', tf.keras.metrics.AUC()])"
      ],
      "metadata": {
        "id": "DTFIvDSvQYg7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7621156c-16e1-443c-f5d9-5306bd0fc895"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 100, 50)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 100, 140)         51240     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 140)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                7050      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,058,596\n",
            "Trainable params: 1,058,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5YoOpVTFIpT",
        "outputId": "4145cea5-88fc-48e6-8b3b-fc1f7aae3128"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "2494/2494 [==============================] - 53s 20ms/step - loss: 0.1458 - accuracy: 0.8500 - auc: 0.7548 - val_loss: 0.1359 - val_accuracy: 0.9940 - val_auc: 0.7917\n",
            "Epoch 2/2\n",
            "2494/2494 [==============================] - 45s 18ms/step - loss: 0.1399 - accuracy: 0.9830 - auc: 0.7789 - val_loss: 0.1345 - val_accuracy: 0.9940 - val_auc: 0.7983\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76e1012810>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_gru = gru_model.predict([test_x], batch_size=1024, verbose=1)\n",
        "y_test_gru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fq3VvU-GJ42",
        "outputId": "ae9d3376-9b88-47bf-a796-c7725c6a6d72"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 2s 19ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11065701, 0.01192847, 0.06048493, 0.00281989, 0.05888237,\n",
              "        0.01000555],\n",
              "       [0.14161117, 0.01972355, 0.08396191, 0.00474785, 0.08038125,\n",
              "        0.01566022],\n",
              "       [0.04477889, 0.00243768, 0.0198296 , 0.00056377, 0.01922448,\n",
              "        0.00228969],\n",
              "       ...,\n",
              "       [0.13987288, 0.01923357, 0.08275157, 0.00466386, 0.07916053,\n",
              "        0.01544101],\n",
              "       [0.12654282, 0.01570627, 0.07356481, 0.00403724, 0.06995023,\n",
              "        0.01377526],\n",
              "       [0.12494688, 0.01531075, 0.07247613, 0.00396425, 0.06886562,\n",
              "        0.01357753]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.evaluate(test_x, test_y, batch_size=1024, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShnCreOu8-VT",
        "outputId": "e7c934a1-78fc-4c2f-ebed-7f2594e2053f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 19ms/step - loss: 0.1373 - accuracy: 0.9976 - auc: 0.8062\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1372605413198471, 0.9976085424423218, 0.8062136173248291]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_val_gru = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_gru, axis=1), average=\"weighted\")\n",
        "f1_score_val_gru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YmtSt9wGV07",
        "outputId": "0d71628b-9457-41d3-da47-ed47b25050b6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_gru[:, i] >= 0.1\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfnnhu22iCwl",
        "outputId": "aa9ef0d1-5a0e-4b81-8b09-6d18a8b122b5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic :\n",
            "0.5881450870154555\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9145761654940144\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.8988179514453957\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU model is faster to train but doesn't perform as good for \"toxic\" comments"
      ],
      "metadata": {
        "id": "52-uJYKviPns"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = testing_clean.copy(deep=True)\n",
        "results[labels] = y_test_gru\n",
        "\n",
        "results.to_csv(\"gru_predictions.csv\")"
      ],
      "metadata": {
        "id": "na-WLir7YxwI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subword embedding (fasttext) : trying to improve toxic obscene and insult labels f1 scores"
      ],
      "metadata": {
        "id": "8TDV-X3PGg50"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_embedding_file = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'"
      ],
      "metadata": {
        "id": "HD6OW4dcIyHx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UshfOGd7julq",
        "outputId": "7bf77df0-287a-42b2-b9b1-295ccb9287d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Kaggle/crawl-300d-2M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGmBwaxmn8CU",
        "outputId": "e9740185-3440-4bdf-c6eb-c1c4624cdc50"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/Kaggle/crawl-300d-2M.vec.zip\n",
            "  inflating: crawl-300d-2M.vec       \n",
            "  inflating: __MACOSX/._crawl-300d-2M.vec  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!realpath crawl-300d-2M.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhyY0Q08oJGk",
        "outputId": "832081b8-64f1-417f-9f28-f648bd3a5dfa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/crawl-300d-2M.vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_embedding_file = \"/content/crawl-300d-2M.vec\""
      ],
      "metadata": {
        "id": "PohxISiOj4a7"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(fasttext_embedding_file))"
      ],
      "metadata": {
        "id": "wP2K1J-CKB3Q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "2YtuIbPcj7ui"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_stack = np.stack(fasttext_index.values())\n",
        "\n",
        "mean = fasttext_stack.mean()\n",
        "std = fasttext_stack.std()\n",
        "print(mean)\n",
        "std"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPf11goBKHjV",
        "outputId": "8a428f8e-331a-45ea-be7c-11feaeb203d7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  if self.run_code(code, result):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0055286596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34703913"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = tokenizer.word_index\n",
        "total_words = min(max_len_embedding, len(index))\n",
        "fasttext_embedding_matrix = np.random.normal(mean, std, (total_words, size))\n",
        "for word, i in index.items():\n",
        "    if i >= max_len_embedding: continue\n",
        "    embedding_vector = index.get(word)\n",
        "    if embedding_vector is not None: fasttext_embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "oXf8jIWyKVm5"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reimplementing the model with the better accuracy using subword embeddings (bidirectional GRU and LSTM models implemented have the same accuracy, so I chose GRU because it was faster during training)"
      ],
      "metadata": {
        "id": "WZj5DHcGK2Q1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(max_len,)),\n",
        "  tf.keras.layers.Embedding(input_dim=max_len_embedding, output_dim=size, input_length=max_len_embedding, weights=[fasttext_embedding_matrix]),\n",
        "  tf.keras.layers.SpatialDropout1D(0.3),\n",
        "  tf.keras.layers.Bidirectional(GRU(70, return_sequences=True)),  tf.keras.layers.GlobalAveragePooling1D(),\n",
        "  tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "  tf.keras.layers.Dropout(0.1),\n",
        "  tf.keras.layers.Dense(nb_labels, activation=\"sigmoid\")\n",
        "])"
      ],
      "metadata": {
        "id": "BtEBZkpHivo7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.summary()\n",
        "\n",
        "gru_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZwS5d4qmGgP",
        "outputId": "12fb3e19-9716-4981-c891-33ef4400620f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 50)           1000000   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 100, 50)          0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 100, 140)         51240     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 140)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                7050      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 306       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,058,596\n",
            "Trainable params: 1,058,596\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gru_model.fit(train_x, train_y, batch_size=32, epochs=2, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJUPt9xtmLjZ",
        "outputId": "4e02053c-f9c8-46cb-d2c4-e71e9cd0f835"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "4488/4488 [==============================] - 65s 12ms/step - loss: 0.1412 - accuracy: 0.9312 - val_loss: 0.1411 - val_accuracy: 0.9940\n",
            "Epoch 2/2\n",
            "4488/4488 [==============================] - 54s 12ms/step - loss: 0.1370 - accuracy: 0.9936 - val_loss: 0.1385 - val_accuracy: 0.9940\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f76e5282350>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_gru_ft = gru_model.predict([test_x], batch_size=1024, verbose=1)\n",
        "y_test_gru_ft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOOn8AwqmTku",
        "outputId": "dc4ca2cf-f58a-4474-901e-7275861db82a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "63/63 [==============================] - 1s 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05896901, 0.00280833, 0.03040114, 0.00048335, 0.02597806,\n",
              "        0.00262513],\n",
              "       [0.11278635, 0.01012663, 0.06459665, 0.00213205, 0.05976514,\n",
              "        0.00824218],\n",
              "       [0.03038359, 0.00088624, 0.01341038, 0.0001424 , 0.0110142 ,\n",
              "        0.00110165],\n",
              "       ...,\n",
              "       [0.11184305, 0.01002471, 0.06387516, 0.0021197 , 0.0590764 ,\n",
              "        0.00823427],\n",
              "       [0.10459071, 0.00925401, 0.05840017, 0.00202596, 0.05386159,\n",
              "        0.00817895],\n",
              "       [0.10371307, 0.00916172, 0.057747  , 0.00201448, 0.05324051,\n",
              "        0.00817185]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1_score_val_gru_ft = f1_score(np.argmax(testing_clean[labels].values, axis=1), np.argmax(y_test_gru_ft, axis=1), average=\"weighted\")\n",
        "f1_score_val_gru_ft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gOIfzjRmYq2",
        "outputId": "bc5bc240-7e2b-469b-b3db-3c17f288bfed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9964142608765079"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg = 0\n",
        "for i, label in enumerate(labels):\n",
        "    print(label, \":\")\n",
        "    pb = y_test_gru_ft[:, i] >= 0.1\n",
        "    score = f1_score(testing_clean[label], pb, average=\"weighted\")\n",
        "    print(score)\n",
        "    avg += score\n",
        "\n",
        "avg /= nb_labels\n",
        "print(\"Average f1-score:\", avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnNbnTlLmdiL",
        "outputId": "ecc88ded-042a-4271-f05b-f3dbcb26b471"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic :\n",
            "0.7024372340635118\n",
            "severe_toxic :\n",
            "0.9914037297776611\n",
            "obscene :\n",
            "0.9143192385431218\n",
            "threat :\n",
            "0.995055710671004\n",
            "insult :\n",
            "0.9203891180722282\n",
            "identity_hate :\n",
            "0.9833378976420114\n",
            "Average f1-score: 0.9178238214615897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fasttext performs better"
      ],
      "metadata": {
        "id": "7NP1LxbAxVcU"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = testing_clean.copy(deep=True)\n",
        "results[labels] = y_test_gru_ft\n",
        "\n",
        "results.to_csv(\"gru_ft_predictions.csv\")"
      ],
      "metadata": {
        "id": "0ylKSfmD7hQZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install casanova"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCdu2YojSPyq",
        "outputId": "a835b826-71bd-489b-9cf0-6500044105bd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting casanova\n",
            "  Downloading casanova-0.18.0-py3-none-any.whl (20 kB)\n",
            "Collecting ebbe<2,>=1.0.0\n",
            "  Downloading ebbe-1.8.0-py3-none-any.whl (10 kB)\n",
            "Collecting file-read-backwards<3,>=2.0.0\n",
            "  Downloading file_read_backwards-2.0.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Installing collected packages: file-read-backwards, ebbe, casanova\n",
            "Successfully installed casanova-0.18.0 ebbe-1.8.0 file-read-backwards-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting results for ensemble model"
      ],
      "metadata": {
        "id": "OqFDM1cIbGEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import casanova\n",
        "\n",
        "with open(\"gru_ft_predictions.csv\") as f, \\\n",
        "     open(\"gru_ft_adjusted_preds.csv\", \"w\") as of:\n",
        "  enricher = casanova.enricher(f, of)\n",
        "\n",
        "  for row in enricher:\n",
        "    toxic_val = float(row[3])\n",
        "    row[3] = str(toxic_val / 0.2)\n",
        "\n",
        "    severe_toxic_val = float(row[4])\n",
        "    row[4] = str(severe_toxic_val / 0.2)\n",
        "\n",
        "    obscene_val = float(row[5])\n",
        "    row[5] = str(obscene_val / 0.2)\n",
        "\n",
        "    threat_val = float(row[6])\n",
        "    row[6] = str(threat_val / 0.2)\n",
        "\n",
        "    insult_val = float(row[7])\n",
        "    row[7] = str(insult_val / 0.2)\n",
        "\n",
        "    identity_hate_val = float(row[8])\n",
        "    row[8] = str(identity_hate_val / 0.2)\n",
        "\n",
        "    enricher.writerow(row)"
      ],
      "metadata": {
        "id": "ytK8wftFR8fT"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"gru_predictions.csv\") as f, \\\n",
        "     open(\"gru_adjusted_preds.csv\", \"w\") as of:\n",
        "  enricher = casanova.enricher(f, of)\n",
        "  toxic_pos = enricher.headers.toxic\n",
        "  severe_toxic_pos = enricher.headers.severe_toxic\n",
        "  obscene_pos = enricher.headers.obscene\n",
        "  threat_pos = enricher.headers.threat\n",
        "  insult_pos = enricher.headers.insult\n",
        "  identity_hate_pos = enricher.headers.identity_hate\n",
        "\n",
        "  for row in enricher:\n",
        "    toxic_val = float(row[toxic_pos])\n",
        "    row[toxic_pos] = str(toxic_val / 0.2)\n",
        "\n",
        "    severe_toxic_val = float(row[severe_toxic_pos])\n",
        "    row[severe_toxic_pos] = str(severe_toxic_val / 0.2)\n",
        "\n",
        "    obscene_val = float(row[obscene_pos])\n",
        "    row[obscene_pos] = str(obscene_val / 0.2)\n",
        "\n",
        "    threat_val = float(row[threat_pos])\n",
        "    row[threat_pos] = str(threat_val / 0.2)\n",
        "\n",
        "    insult_val = float(row[insult_pos])\n",
        "    row[insult_pos] = str(insult_val / 0.2)\n",
        "\n",
        "    identity_hate_val = float(row[identity_hate_pos])\n",
        "    row[identity_hate_pos] = str(identity_hate_val / 0.2)\n",
        "\n",
        "    enricher.writerow(row)"
      ],
      "metadata": {
        "id": "j8g6gVnSZk7M"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yvcY-9PaTXs",
        "outputId": "52708430-d194-4183-9539-214ea985e50a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Kaggle/predictions/lstm_predictions.csv\") as f, \\\n",
        "     open(\"lstm_adjusted_preds.csv\", \"w\") as of:\n",
        "  enricher = casanova.enricher(f, of)\n",
        "  toxic_pos = enricher.headers.toxic\n",
        "  severe_toxic_pos = enricher.headers.severe_toxic\n",
        "  obscene_pos = enricher.headers.obscene\n",
        "  threat_pos = enricher.headers.threat\n",
        "  insult_pos = enricher.headers.insult\n",
        "  identity_hate_pos = enricher.headers.identity_hate\n",
        "\n",
        "  for row in enricher:\n",
        "    toxic_val = float(row[toxic_pos])\n",
        "    row[toxic_pos] = str(toxic_val / 0.2)\n",
        "\n",
        "    severe_toxic_val = float(row[severe_toxic_pos])\n",
        "    row[severe_toxic_pos] = str(severe_toxic_val / 0.2)\n",
        "\n",
        "    obscene_val = float(row[obscene_pos])\n",
        "    row[obscene_pos] = str(obscene_val / 0.2)\n",
        "\n",
        "    threat_val = float(row[threat_pos])\n",
        "    row[threat_pos] = str(threat_val / 0.2)\n",
        "\n",
        "    insult_val = float(row[insult_pos])\n",
        "    row[insult_pos] = str(insult_val / 0.2)\n",
        "\n",
        "    identity_hate_val = float(row[identity_hate_pos])\n",
        "    row[identity_hate_pos] = str(identity_hate_val / 0.2)\n",
        "\n",
        "    enricher.writerow(row)"
      ],
      "metadata": {
        "id": "IV7Qv9rtZquU"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "pH3jb57Haxix"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}